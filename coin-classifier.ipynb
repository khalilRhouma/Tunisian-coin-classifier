{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import layers\nfrom keras import Sequential\nfrom keras import models\nfrom keras import optimizers\nfrom sklearn.model_selection import train_test_split # split the data into train and test set\nimport seaborn as sns\nimport cv2\nimport numpy as np\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport random\nimport gc\nimport matplotlib.image as mpimg\nimport csv\nfrom tqdm import tqdm\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load Dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_dir = \"/kaggle/input/ieeeensiai/train/train\"\ntest_dir = \"/kaggle/input/ieeeensiai/test/test\"\n\ntrain_set = [\"/kaggle/input/ieeeensiai/train/train/{}\".format(i) for i in os.listdir(train_dir)] # get the image training set\ntest_set = [\"/kaggle/input/ieeeensiai/test/test/{}\".format(i) for i in os.listdir(test_dir)] # get the image test set\ntrain_set= train_set[:11000]\ntest_set= test_set[:5000]\ndict_labels = {'10':0,'20':1,'50':2,'100':3,'200':4,'500':5,'1000':6,'2000':7,'5000':8}\nrandom.shuffle(train_set)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# displaying image data\ndef display_data(image):\n    img=mpimg.imread(image)\n    imgplot = plt.imshow(img)\n    plt.show()\ndisplay_data(train_set[8])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Get labels from CSV file"},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = {}\nwith open('/kaggle/input/ieeeensiai/train.csv') as csv_file:\n    csv_reader = csv.reader(csv_file, delimiter=',')\n    for row in csv_reader:\n        if row[0]!= 'img':\n            labels[row[0]] = row[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def process_images(list_of_images, labels):\n    X = []\n    Y = []\n#     vgg_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32)\n    for path in tqdm(list_of_images):\n        im = cv2.imread(path)\n        im = im[:,::-1]\n        X.append(im)\n#         im = im - vgg_mean\n        if labels:\n            label = path.split('/')\n            label = label[-1]\n            label = label.split('.')[0]\n            categ = [0.]*9\n            categ[dict_labels[labels[label]]] = 1.\n            Y.append(categ)\n    return X, Y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# processing data and making labels\nX, Y = process_images(train_set, labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# delete unnecessary data\ndel train_set\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert to array\nX = np.array(X)\nY = np.array(Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test image with corresponding label\ndef print_label(y):\n    for key, value in dict_labels.items():\n        index = list(y).index(1.)\n        if index == value:\n            return(key)\n# testing the labeled data\nplt.imshow(X[6])\nplt.title(print_label(Y[6]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('image data shape', X.shape)\nprint('label shape', Y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.20)\n\nprint(\"shape of train images is :\",X_train.shape)\nprint(\"shape of validation images is :\",X_val.shape)\nprint(\"shape of train labels is :\",y_train.shape)\nprint(\"shape of validation labels is :\",y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# clear memory\ndel X\ndel Y\ngc.collect()\n\n# get the lenght of train and validation data\nntrain = len(X_train)\nnval = len(X_val)\n\n# bach_size\nbatch_size = 64","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.Sequential()\n# Conv Block 1\n\nmodel.add(layers.Conv2D(64, (3, 3), input_shape=(224,224,3), activation='relu', padding='same'))\n\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n\nmodel.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n\n\n# Conv Block 2\n\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n\nmodel.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n\n\n# Conv Block 3\n\nmodel.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n\nmodel.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n\nmodel.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n\nmodel.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n\n\n# Conv Block 4\n\nmodel.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n\nmodel.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n\nmodel.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n\nmodel.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n\n\n# Conv Block 5\n\nmodel.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n\nmodel.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n\nmodel.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n\nmodel.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n\n\n# FC layers\n\nmodel.add(layers.Flatten())\n\nmodel.add(layers.Dense(4096, activation='relu'))\n\nmodel.add(layers.Dense(4096, activation='relu'))\n\nmodel.add(layers.Dense(9, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# compile the model\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create the augmentation configuration\n# this helps prevent overfitting, since we use a small dataset\ntrain_datagen = ImageDataGenerator(rescale=1./255,\n                                    rotation_range=40,\n                                    width_shift_range=0.2,\n                                    height_shift_range=0.2,\n                                    shear_range = 0.2,\n                                    horizontal_flip=True)\nval_datagen = ImageDataGenerator(rescale=1./255) # for validation dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creat the image generators\ntrain_generator = train_datagen.flow(X_train, y_train , batch_size=batch_size)\nval_generator = val_datagen.flow(X_val, y_val , batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# the training part\n# we train for 64 epochs\nhistory = model.fit_generator(train_generator,\n                             steps_per_epoch=ntrain // batch_size,\n                             epochs=32,\n                             validation_data=val_generator,\n                             validation_steps=nval // batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Save the model\n# model.save('model_keras.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# process the test set \nX_test,_ = process_images(test_set[:1000], labels=[])\nx = np.array(X_test)\ntest_datagen = ImageDataGenerator(rescale=1./255)\nx_test = test_datagen.flow(x, batch_size=1)\npredected = model.predict_generator(x_test,steps=len(x_test))\nprint(len(predected))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make predection\npredect = []\nfor pre in predected:\n    index = list(pre).index(max(list(pre)))\n    for key,value in dict_labels.items():\n        if value ==index:\n            predect.append(key)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print some predection\nind = 40\npred = model.predict(x_test[ind])\nlist_label = list(pred[0,])\nprint(list_label)\nmaximum = max(list_label)\nindex = list_label.index(maximum)\ntext_label = ''\nfor key,val in dict_labels.items():\n    if val ==index:\n        text_label=key\nplt.title('it is a '+ text_label +\" coin\")\nimgplot = plt.imshow(x_test[ind][0])\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}